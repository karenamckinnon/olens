{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own Observational Large Ensemble\n",
    "\n",
    "This code creates an Observational Large Ensemble based on the statistics of the observations and the forced trend from the NCAR CESM1 LENS.  \n",
    "\n",
    "A limited set of results is discussed in McKinnon and Deser, currently submitted to Journal of Climate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset, MFDataset\n",
    "from mpl_toolkits.basemap import Basemap, cm, maskoceans, shiftgrid\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    x = x - np.mean(x)\n",
    "    result = np.correlate(x, x, mode = 'full')\n",
    "    result /= result[np.shape(x)[0] - 1]\n",
    "    return result[result.size/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcFDR(lon, lat, obsRatio, nullRatio, FDR, testType, domask):\n",
    "    # Calculate gridbox-wise significance based on controlling the False Discovery Rate \n",
    "    # see, e.g., Wilks, 2016, BAMS\n",
    "    \n",
    "    # get ocean mask\n",
    "    if domask:\n",
    "        var = obsRatio\n",
    "        if np.max(lon) > 180:\n",
    "            lon2 = lon\n",
    "            lon2[lon2 > 180] -= 360\n",
    "            var2 = var\n",
    "        else:\n",
    "            var2 = var\n",
    "            lon2 = lon\n",
    "        lons, lats = np.meshgrid(lon2, lat)\n",
    "        var3 = maskoceans(lons, lats, var2, resolution = 'l')\n",
    "\n",
    "        obsRatio = np.ma.masked_where(np.ma.getmask(var3), obsRatio)\n",
    "        maskMat = np.repeat(obsRatio.mask[np.newaxis, :], np.shape(nullRatio)[0], axis = 0)\n",
    "        nullRatio = np.ma.masked_where(maskMat, nullRatio)\n",
    "\n",
    "    nmembers = np.shape(nullRatio)[0]\n",
    "    \n",
    "    pvalA = np.sum(nullRatio > obsRatio[np.newaxis, :], axis = 0)/float(nmembers)\n",
    "    pvalB = np.sum(nullRatio < obsRatio[np.newaxis, :], axis = 0)/float(nmembers)\n",
    "    \n",
    "    if testType == 'upper': # we expect our value to be higher than the null\n",
    "        pval = pvalA\n",
    "    elif testType == 'lower': # we expect our value to be lower than the null\n",
    "        pval = pvalB\n",
    "    elif testType == 'both': # we don't know and want to do a two-sided test\n",
    "        pval = 2.*np.min(np.vstack((pvalA, pvalB)), axis = 0) \n",
    "        # need to remask for some reason\n",
    "        if domask:\n",
    "            pval = np.ma.masked_where(np.ma.getmask(var3), pval)\n",
    "\n",
    "    # pval = np.sum(nullRatio > obsRatio[np.newaxis, :], axis = 0)/float(nmembers)\n",
    "\n",
    "    pvalSorted = np.sort(pval)\n",
    "\n",
    "    if domask:\n",
    "        N = float(np.sum(~np.ma.getmask(pvalSorted)))\n",
    "    else:\n",
    "        N = float(np.shape(pvalSorted)[0])\n",
    "    \n",
    "    cutoff = np.arange(1, np.shape(pval)[0] + 1)/N*FDR\n",
    "    \n",
    "    cutoffIdx = (np.where(pvalSorted > cutoff))[0][0]\n",
    "    print pvalSorted[cutoffIdx]\n",
    "    \n",
    "    notSigVals = pval > pvalSorted[cutoffIdx]\n",
    "        \n",
    "    return notSigVals, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maskOceansKAM(lon, lat, var):\n",
    "    # just a wrapper function for masking ocean\n",
    "    \n",
    "    lon2 = lon.copy()\n",
    "    lon2[lon2 > 180] -= 360\n",
    "\n",
    "    lons, lats = np.meshgrid(lon2, lat)\n",
    "    var3 = maskoceans(lons, lats, var, resolution = 'l')\n",
    "    lats = lats.reshape(np.shape(var3))\n",
    "    var3 = np.ma.masked_where(lats < -60, var3) # and Antarctica\n",
    "    \n",
    "    return var3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "season = 'DJF' # 'DJF' or 'JJA' or 'MAM' or 'SON' or 'ALL'\n",
    "# in CESM speak, rename obs to the same at command line using ncrename\n",
    "# weird naming convention for Z3 because CESM field is all levels\n",
    "varname = 'PSL' # 'TREFHT' or 'PSL' or 'Z3' or 'PREC' or 'T' or 'TS'\n",
    "if varname == 'Z3':\n",
    "    is3d = 1\n",
    "    levUse = 500\n",
    "elif varname == 'T':\n",
    "    is3d = 1\n",
    "    levUse = 1000\n",
    "else:\n",
    "    is3d = 0\n",
    "    \n",
    "# which dataset for the obs? \n",
    "# for temperature (TREFHT, T, or TS): 'BEST'\n",
    "# for sea level pressure and geopotential height: '20CRV2c' or 'NCEP'\n",
    "# for precip: 'GPCC'\n",
    "obsname = '20CRV2c'  \n",
    "\n",
    "# parameters for calculating interannual variability \n",
    "yrStart, yrEnd = 1921, 2014\n",
    "\n",
    "# 20CRV2c ends in 2014\n",
    "# NCEP starts in 1949\n",
    "if obsname == '20CRV2c':\n",
    "    if yrEnd > 2014:\n",
    "        print 'Warning!! Years are being changed based on data availability. Proceed with caution.'\n",
    "        yrEnd = 2014\n",
    "if obsname == 'NCEP':\n",
    "    if yrStart < 1949:\n",
    "        print 'Warning!! Years are being changed based on data availability. Proceed with caution.'\n",
    "        yrStart = 1949\n",
    "yrs = np.arange(yrStart, yrEnd + 1, 1)\n",
    "nyrs = np.shape(yrs)[0]\n",
    "trendType1 = 'EM' # use the NCAR CESM1 ensemble mean as a basis for estimating the forced component\n",
    "\n",
    "# parameters for assessing variability in trends\n",
    "# i.e. may want to use full record for sampling internal variability, but then only examine\n",
    "# a shorter period for the trend analysis\n",
    "yrStartTrend, yrEndTrend = 1965, 2014\n",
    "if obsname == '20CRV2c':\n",
    "    if yrEndTrend > 2014:\n",
    "        print 'Warning!! Years are being changed based on data availability. Proceed with caution.'\n",
    "        yrEndTrend = 2014\n",
    "if obsname == 'NCEP':\n",
    "    if yrStartTrend < 1949:\n",
    "        print 'Warning!! Years are being changed based on data availability. Proceed with caution.'\n",
    "        yrStartTrend = 1949\n",
    "yrsTrend = np.arange(yrStartTrend, yrEndTrend + 1, 1)\n",
    "nyrsTrend = np.shape(yrsTrend)[0]\n",
    "trendType2 = 'linear' # for summarizing spread across LENS and OLENS\n",
    "\n",
    "# spatial domain\n",
    "region = 'global'\n",
    "if region == 'global':\n",
    "    latRange = -90, 90\n",
    "    lonRange = 0, 360\n",
    "\n",
    "# bootstrapping params\n",
    "nboot = 1000\n",
    "blocksize = 2\n",
    "\n",
    "# false discovery rate \n",
    "FDR = 0.1\n",
    "\n",
    "# do a hash of relevant parameters\n",
    "paramHash = hash(tuple((season, varname, obsname, yrStart, yrEnd, trendType1, yrStartTrend, yrEndTrend,\\\n",
    "                 trendType2, latRange, lonRange, nboot, blocksize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file locations\n",
    "Both output from the NCAR CESM1 LENS and various observational datasets are needed.  \n",
    "\n",
    "Output from LENS is available on glade (yellowstone/cheyenne).  \n",
    "\n",
    "All data are freely available online at URLs listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LENS data\n",
    "if varname == 'PREC': # have to combine large scale and convective\n",
    "    modelDir = '/glade/p/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/monthly/' + varname + 'C'\n",
    "    namesHist = sorted(glob.glob(modelDir + '/b.e11.B20TRC5CNBDRD.f09_g16*' + varname + '*200512.nc'))[:40] # last two runs not available for future\n",
    "    namesFuture = sorted(glob.glob(modelDir + '/b.e11.BRCP85C5CNBDRD.f09_g16*' + varname + '*200601-*.nc'))\n",
    "    \n",
    "    modelDirL = '/glade/p/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/monthly/' + varname + 'L'\n",
    "    namesHistL = sorted(glob.glob(modelDirL + '/b.e11.B20TRC5CNBDRD.f09_g16*' + varname + '*200512.nc'))[:40] # last two runs not available for future\n",
    "    namesFutureL = sorted(glob.glob(modelDirL + '/b.e11.BRCP85C5CNBDRD.f09_g16*' + varname + '*200601-*.nc'))\n",
    "else:\n",
    "    modelDir = '/glade/p/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/monthly/' + varname\n",
    "    namesHist = sorted(glob.glob(modelDir + '/b.e11.B20TRC5CNBDRD.f09_g16*' + varname + '*200512.nc'))[:40] # last two runs not available for future\n",
    "    namesFuture = sorted(glob.glob(modelDir + '/b.e11.BRCP85C5CNBDRD.f09_g16*' + varname + '*200601-*.nc'))\n",
    "\n",
    "# observational data\n",
    "# BEST: http://berkeleyearth.lbl.gov/auto/Global/Gridded/Land_and_Ocean_LatLong1.nc\n",
    "# 20CRV2c: https://www.esrl.noaa.gov/psd/data/gridded/data.20thC_ReanV2c.html\n",
    "# slp: ftp://ftp.cdc.noaa.gov/Datasets/20thC_ReanV2c/Monthlies/monolevel/prmsl.mon.mean.nc\n",
    "# geopotential height: ftp://ftp.cdc.noaa.gov/Datasets/20thC_ReanV2c/Monthlies/pressure/hgt.mon.mean.nc\n",
    "\n",
    "dataDir = '' # INSERT DIRECTORY WHERE FILES WERE SAVED HERE\n",
    "if obsname == 'BEST':\n",
    "    dataName = 'Land_and_Ocean_LatLong1_' + varname + '.nc'\n",
    "elif (obsname == '20CRV2c') & (varname == 'PSL'):\n",
    "    dataName = 'prmsl.mon.mean.nc'\n",
    "elif (obsname == '20CRV2c') & (varname == 'Z3'):\n",
    "    dataName = 'hgt500.mon.mean.nc'\n",
    "elif (obsname == 'NCEP') & (varname == 'PSL'):\n",
    "    dataName = 'slp.mon.mean.nc'\n",
    "elif (obsname == 'GPCC'):\n",
    "    dataName = 'precip.mon.combined.total.v7.nc'\n",
    "\n",
    "    \n",
    "# rename obs to model speak\n",
    "ds = Dataset(dataDir + dataName, 'r')\n",
    "if (varname not in ds.variables.keys()):\n",
    "#     import subprocess\n",
    "#     subprocess.call('module load nco')\n",
    "#     strUse = 'ncrename -v temperature,' + varname + ' ' + dataDir + dataName\n",
    "#     subprocess.call(strUse, shell = True, executable = '/bin/bash')\n",
    "# The above not working for unclear reasons\n",
    "    print 'Change the varname in data to ' + varname\n",
    "    raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these paths to desired locations where output will be saved\n",
    "outputDir = '' # WHERE SHOULD OUTPUT BE SAVED?\n",
    "scratchDir = '' # WHERE SHOULD LARGE OUTPUT BE SAVED?\n",
    "LENSoutput = '' # WHERE SHOULD INTERMEDIATE LENS FILES GO?\n",
    "dataoutput = '' # WHERE SHOULD INTERMEDIATE DATA FILES GO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series of climate modes\n",
    "\n",
    "Get observed and modeled time series of ENSO, PDO, and AMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orthogonalize_timeseries(modeValNorm, nModes, nyrs):\n",
    "# Create orthogonal time series from the mode time series\n",
    "\n",
    "    from eofs.standard import Eof\n",
    "    if nModes != np.shape(modeValNorm)[-1]:\n",
    "        modeValNorm = np.transpose(modeValNorm)\n",
    "        \n",
    "    solver = Eof(modeValNorm)\n",
    "    varExp = solver.varianceFraction(neigs=nModes)\n",
    "    eofs = solver.eofs(neofs = nModes) \n",
    "    # Orthogonal time series\n",
    "    # retain unity standard deviation\n",
    "    modeValNormO = solver.pcs(npcs = nModes, pcscaling = 1)\n",
    "    \n",
    "\n",
    "    return modeValNormO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_surrogates_1d(ts):\n",
    "    '''\n",
    "    Use the inverse fourier transform to shuffle phases.\n",
    "    '''\n",
    "    \n",
    "    ts_fourier  = np.fft.fft(ts)\n",
    "    \n",
    "    if len(ts) % 2 == 1:\n",
    "        random_phases = np.exp(np.random.uniform(0,np.pi,len(ts)/2+1)*1.0j)\n",
    "        random_phases = np.hstack((-random_phases[::-1], random_phases[1:]))\n",
    "    else:\n",
    "        random_phases = np.exp(np.random.uniform(0,np.pi,len(ts)/2)*1.0j)\n",
    "        random_phases = np.hstack((-random_phases[::-1], random_phases))\n",
    "    ts_fourier_new = ts_fourier*random_phases\n",
    "    new_ts = np.real(np.fft.ifft(ts_fourier_new))\n",
    "    \n",
    "    return new_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed time series\n",
    "import requests\n",
    "\n",
    "modeNames = 'MEI', 'PDO', 'AMO'\n",
    "nModes = len(modeNames)\n",
    "urlMEI = 'https://www.esrl.noaa.gov/psd/gcos_wgsp/Timeseries/Data/nino34.long.data'\n",
    "urlPDO = 'http://research.jisao.washington.edu/pdo/PDO.latest.txt'\n",
    "urlAMO = 'https://www.esrl.noaa.gov/psd/data/correlation/amon.us.long.data'\n",
    "\n",
    "lagTime = 0 # in months\n",
    "\n",
    "modeHash = hash(tuple((urlMEI, urlPDO, urlAMO, str(lagTime), str(yrs), season, modeNames)))\n",
    "modeSaveName = outputDir + 'modeVals.' + str(modeHash) + '.npz'\n",
    "\n",
    "# Get each of these indices for the correct season\n",
    "if (not os.path.isfile(modeSaveName)):\n",
    "    \n",
    "    modeVal = np.empty((nyrs, len(modeNames)))\n",
    "    for nn, nameUse in enumerate(modeNames):\n",
    "        urlUse = eval('url' + nameUse)\n",
    "        r = requests.get(urlUse)\n",
    "        data = r.content\n",
    "        data = data.split()\n",
    "        if nameUse == 'MEI':\n",
    "            headerLines = 2\n",
    "            footerLines = -6\n",
    "            ncolperrow = 13\n",
    "        elif nameUse == 'AMO':\n",
    "            headerLines = 2\n",
    "            footerLines = -12\n",
    "            ncolperrow = 13   \n",
    "        elif nameUse == 'PDO':\n",
    "            headerLines = 172\n",
    "            footerLines = -50\n",
    "            ncolperrow = 13\n",
    "\n",
    "        data = np.array(data[headerLines:footerLines])\n",
    "        nrows = np.shape(data)[0]/ncolperrow\n",
    "        dataMat = np.reshape(data, (nrows, ncolperrow))\n",
    "\n",
    "        # pull out relevant years and months to get seasonal averages \n",
    "        modeMonths = np.arange(1, 13)\n",
    "        modeYears = dataMat[:, 0]\n",
    "        if nameUse == 'PDO':\n",
    "            modeYears = np.array([line.translate(None, '**') for line in modeYears])\n",
    "\n",
    "        modeYears = modeYears.astype('int')\n",
    "        nmodemonths, nmodeyears = np.shape(modeMonths)[0], np.shape(modeYears)[0]\n",
    "        modeVals = dataMat[:, 1:].flatten().astype('float') # remove years\n",
    "\n",
    "        # make matrices to pull out correct months and years\n",
    "        modeMonths = np.repeat(modeMonths[np.newaxis,:], nmodeyears, axis = 0).flatten()\n",
    "        modeYears = np.repeat(modeYears[:, np.newaxis], nmodemonths, axis = -1).flatten()\n",
    "\n",
    "        # account for lag\n",
    "        modeMonthsR = np.roll(modeMonths, -lagTime)\n",
    "        modeYearsR = np.roll(modeYears, -lagTime) \n",
    "\n",
    "\n",
    "        for counter, yy in enumerate(yrs):\n",
    "\n",
    "            if season == 'DJF':\n",
    "                idxTime = ((modeMonthsR >= 1) & (modeMonthsR <= 2) & (modeYearsR == yy)) | \\\n",
    "                    ((modeMonthsR == 12) & (modeYearsR == yy-1))\n",
    "            elif season == 'JJA':\n",
    "                idxTime = ((modeMonthsR >= 6) & (modeMonthsR <= 8)) & (modeYearsR == yy)\n",
    "            elif season == 'MAM':\n",
    "                idxTime = ((modeMonthsR >= 3) & (modeMonthsR <= 5)) & (modeYearsR == yy)\n",
    "            elif season == 'SON':\n",
    "                idxTime = ((modeMonthsR >= 9) & (modeMonthsR <= 11)) & (modeYearsR == yy) \n",
    "            elif season == 'ALL':\n",
    "                idxTime = (modeYearsR == yy)\n",
    "            else:\n",
    "                print 'Need to specify a canonical 3 month season, or ALL for full year'\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "            dummy = np.mean(modeVals[idxTime])\n",
    "            normVal = np.std(dummy)\n",
    "            modeVal[counter, nn] = dummy\n",
    "            \n",
    "    modeValNorm = (modeVal - np.mean(modeVal, axis = 0))/np.std(modeVal, axis = 0)\n",
    "    \n",
    "    modeValNormO = orthogonalize_timeseries(modeValNorm, nModes, nyrs)\n",
    "    modeValNormO = (modeValNormO - np.mean(modeValNormO, axis = 0))/np.std(modeValNormO, axis = 0)\n",
    "    # First EOF = like MEI and PDO\n",
    "    # Second EOF = like AMO\n",
    "    # Third EOF = remainders (most like MEI and PDO)\n",
    "    \n",
    "    np.savez(modeSaveName, modeValNorm = modeValNorm, modeValNormO = modeValNormO)\n",
    "\n",
    "else:\n",
    "    print 'Loading observational modes'\n",
    "    ds = np.load(modeSaveName)\n",
    "    modeValNormO = ds['modeValNormO'] # orthogonal time series\n",
    "    modeValNorm = ds['modeValNorm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get modeled modes\n",
    "modeDir = '/glade/p/cesmLE/CESM-CAM5-BGC-LE/CVDP/1920-2015/'\n",
    "\n",
    "yrSpan = (str(modeDir.split('/')[-2]))[:4], (str(modeDir.split('/')[-2]))[5:]\n",
    "# time in these files is in a non-python friendly format. Get from directory. \n",
    "time = pd.date_range(start = '1/' + yrSpan[0], end = '1/' + str(int(yrSpan[-1])+1), freq = 'M')\n",
    "\n",
    "ENSOname = 'nino34'\n",
    "PDOname = 'pdo_timeseries_mon'\n",
    "AMOname = 'amo_timeseries_mon'\n",
    "\n",
    "modeNames = 'ENSO', 'PDO', 'AMO'\n",
    "nModes = len(modeNames)\n",
    "\n",
    "if np.remainder(nyrs, 2) == 1:\n",
    "    modeYrs = np.arange(yrStart - 1, yrEnd + 1, 1)\n",
    "else:\n",
    "    modeYrs = np.arange(yrStart, yrEnd + 1, 1)\n",
    "\n",
    "ensMembers = np.hstack((np.arange(1, 36), np.arange(101, 106)))\n",
    "nMembers = np.shape(ensMembers)[0]\n",
    "\n",
    "modeHash = hash(tuple((modeDir, modeNames, ensMembers.tostring(), str(lagTime), str(yrs), season)))\n",
    "modeSaveName = outputDir + 'LENS.modeVals.' + str(modeHash) + '.npz'\n",
    "\n",
    "if (not os.path.isfile(modeSaveName)):\n",
    "\n",
    "    modeValNorm_LENS = np.empty((nyrs, nModes, nMembers))\n",
    "    modeValNormO_LENS = np.empty((nyrs, nModes, nMembers))\n",
    "\n",
    "    for counter in np.arange(nMembers):\n",
    "        fname = modeDir + 'CESM1-CAM5-BGC-LE_#' + str(ensMembers[counter]) + '.cvdp_data.1920-2015.nc'\n",
    "\n",
    "        with Dataset(fname, 'r') as ds:\n",
    "\n",
    "            modeVal = np.empty((nyrs, nModes))\n",
    "            for mm, mode in enumerate(modeNames):\n",
    "                varUse = eval(mode + 'name')\n",
    "                modeVals = ds[varUse][:]\n",
    "\n",
    "                # account for lag\n",
    "                modeMonthsR = np.roll(time.month, -lagTime)\n",
    "                modeYearsR = np.roll(time.year, -lagTime) \n",
    "\n",
    "                for jj, yy in enumerate(yrs):\n",
    "\n",
    "                    if season == 'DJF':\n",
    "                        idxTime = ((modeMonthsR >= 1) & (modeMonthsR <= 2) & (modeYearsR == yy)) | \\\n",
    "                            ((modeMonthsR == 12) & (modeYearsR == yy-1))\n",
    "                    elif season == 'JJA':\n",
    "                        idxTime = ((modeMonthsR >= 6) & (modeMonthsR <= 8)) & (modeYearsR == yy)\n",
    "                    elif season == 'MAM':\n",
    "                        idxTime = ((modeMonthsR >= 3) & (modeMonthsR <= 5)) & (modeYearsR == yy)\n",
    "                    elif season == 'SON':\n",
    "                        idxTime = ((modeMonthsR >= 9) & (modeMonthsR <= 11)) & (modeYearsR == yy) \n",
    "                    elif season == 'ALL':\n",
    "                        idxTime = (modeYearsR == yy)\n",
    "                    else:\n",
    "                        print 'Need to specify a canonical 3 month season, or ALL for full year'\n",
    "                        raise KeyboardInterrupt\n",
    "\n",
    "                    dummy = np.mean(modeVals[idxTime])\n",
    "                    normVal = np.std(dummy)\n",
    "                    modeVal[jj, mm] = dummy\n",
    "\n",
    "            modeValNorm = (modeVal - np.mean(modeVal, axis = 0))/np.std(modeVal, axis = 0)\n",
    "\n",
    "            modeValNormO = orthogonalize_timeseries(modeValNorm, nModes, nyrs)\n",
    "            modeValNormO = (modeValNormO - np.mean(modeValNormO, axis = 0))/np.std(modeValNormO, axis = 0)\n",
    "\n",
    "            modeValNorm_LENS[:, :, counter] = modeValNorm\n",
    "            modeValNormO_LENS[:, :, counter] = modeValNormO\n",
    "    \n",
    "    np.savez(modeSaveName, modeValNorm_LENS = modeValNorm_LENS, modeValNormO_LENS = modeValNormO_LENS)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    ds = np.load(modeSaveName)\n",
    "    modeValNorm_LENS = ds['modeValNorm_LENS']\n",
    "    modeValNormO_LENS = ds['modeValNormO_LENS']\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate forced trend in model\n",
    "Using approach of Dai et al (2015), assume that the locally forced temperature trend scales linearly with the global mean, ensemble mean temperature trend, and the analog for other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (trendType1 == 'EM') | (trendType2 == 'EM'):\n",
    "    \n",
    "    emTrendFile = outputDir + 'cesm.EM.' + season + '.' + varname + '.' + str(yrStart) + '.' + str(yrEnd) + '.npy' \n",
    "    \n",
    "    if os.path.isfile(emTrendFile):\n",
    "        print 'Loading global mean, ensemble mean trend'\n",
    "        EMglobal = np.load(emTrendFile)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        globalMeanTemp = np.empty((nyrs, len(namesHist)))\n",
    "\n",
    "        for counter in np.arange(len(namesHist)):\n",
    "\n",
    "            # read in historical simulation for first part\n",
    "            ensNumber = (((namesHist[counter].split('/'))[-1]).split('.'))[4]\n",
    "\n",
    "            print 'Calculating global average trend for ' + season + ' in CESM ens ' + ensNumber\n",
    "            timeSpan = (((namesHist[counter].split('/'))[-1]).split('.'))[-2]\n",
    "            fileBeginYr = (str(timeSpan)[:4])\n",
    "            fileBeginMo = (str(timeSpan)[4:6])\n",
    "            fileEndYr = int(str(timeSpan)[7:11])\n",
    "            fileEndMo = int(str(timeSpan)[11:13])\n",
    "            fid1 = Dataset(namesHist[counter], 'r')\n",
    "            if varname == 'PREC':\n",
    "                fid1L = Dataset(namesHistL[counter], 'r')\n",
    "                \n",
    "            time0 = fid1.variables['time'][:]\n",
    "            ntime = time0.shape[0]\n",
    "            time1 = pd.date_range(fileBeginMo + '/15/' + fileBeginYr, periods = ntime, freq = 'M')\n",
    "\n",
    "            lat = fid1.variables['lat'][:]\n",
    "            lon = fid1.variables['lon'][:]\n",
    "\n",
    "            # load in values that are in the timespan\n",
    "            idx1 = (time1.year >= yrStart - 1) & (time1.year <= yrEnd) # need one year earlier for the D in DJF\n",
    "\n",
    "            if is3d:\n",
    "                lev = fid1.variables['lev'][:]\n",
    "                idxLev = np.argmin(np.abs(lev - levUse))\n",
    "                T1 = (fid1.variables[varname][idx1, idxLev, :, :]).squeeze()\n",
    "            elif varname == 'PREC':\n",
    "                T1L = fid1L.variables[varname + 'L'][idx1, :, :] # large scale\n",
    "                T1C = fid1.variables[varname + 'C'][idx1, :, :] # convective\n",
    "                T1 = T1L + T1C\n",
    "            else:\n",
    "                T1 = fid1.variables[varname][idx1, :, :]\n",
    "\n",
    "            # now read in future\n",
    "            timeSpan = (((namesFuture[counter].split('/'))[-1]).split('.'))[-2]\n",
    "            fileBeginYr = (str(timeSpan)[:4])\n",
    "            fileBeginMo = (str(timeSpan)[4:6])\n",
    "            fileEndYr = int(str(timeSpan)[7:11])\n",
    "            fileEndMo = int(str(timeSpan)[11:13])\n",
    "\n",
    "            fid2 = Dataset(namesFuture[counter], 'r')\n",
    "            if varname == 'PREC':\n",
    "                fid2L = Dataset(namesFutureL[counter], 'r') \n",
    "                \n",
    "            time0 = fid2.variables['time'][:]\n",
    "            ntime = time0.shape[0]\n",
    "            time2 = pd.date_range(fileBeginMo + '/15/' + fileBeginYr, periods = ntime, freq = 'M')\n",
    "\n",
    "            # load in values that are in the timespan\n",
    "            idx2 = (time2.year >= yrStart - 1) & (time2.year <= yrEnd) # need one year earlier for the D in DJF\n",
    "\n",
    "            if is3d:\n",
    "                lev = fid2.variables['lev'][:]\n",
    "                idxLev = np.argmin(np.abs(lev - levUse))\n",
    "                T2 = (fid2.variables[varname][idx2, idxLev, :, :]).squeeze()\n",
    "            elif varname == 'PREC':\n",
    "                T2L = fid2L.variables[varname + 'L'][idx2, :, :] # large scale\n",
    "                T2C = fid2.variables[varname + 'C'][idx2, :, :] # convective\n",
    "                T2 = T2L + T2C\n",
    "            else:\n",
    "                T2 = fid2.variables[varname][idx2, :, :]\n",
    "\n",
    "            T = np.concatenate((T1, T2), axis = 0)\n",
    "            time = pd.date_range('1/1/' + str(yrStart - 1), periods = T.shape[0], freq = 'M')\n",
    "\n",
    "            mlat = lat.shape[0]\n",
    "            mlon = lon.shape[0]\n",
    "\n",
    "            # take seasonal average \n",
    "            tempseasonal = np.empty((nyrs, mlat, mlon))\n",
    "            timeseasonal = []\n",
    "            for ct in np.arange(nyrs):\n",
    "                yr = yrs[ct]\n",
    "                if season == 'DJF':\n",
    "                    idxTime = (((time.month >= 1) & (time.month <= 2)) & (time.year == yr)) | (((time.month == 12) & (time.year == yr - 1)))\n",
    "                elif season == 'JJA':\n",
    "                    idxTime = ((time.month >= 6) & (time.month <= 8)) & (time.year == yr)\n",
    "                elif season == 'MAM':\n",
    "                    idxTime = ((time.month >= 3) & (time.month <= 5)) & (time.year == yr)\n",
    "                elif season == 'SON':\n",
    "                    idxTime = ((time.month >= 9) & (time.month <= 11)) & (time.year == yr)\n",
    "                elif season == 'ALL':\n",
    "                    idxTime = (time.year == yr)\n",
    "                else:\n",
    "                    print 'Need to specify a canonical 3 month season'\n",
    "                    raise KeyboardInterrupt\n",
    "                tempseasonal[ct, :, :] = np.mean(T[idxTime, :, :], axis = 0)\n",
    "                timeseasonal.append(pd.to_datetime((time[idxTime])[-1])) \n",
    "\n",
    "            # change units \n",
    "            if varname == 'PREC':\n",
    "                modelUnits = fid1.variables[varname + 'C'].units\n",
    "            else:\n",
    "                modelUnits = fid1.variables[varname].units\n",
    "                \n",
    "            if modelUnits == 'K':\n",
    "                tempseasonal -= 273.15\n",
    "                modelUnits = 'degC'\n",
    "            elif modelUnits == 'Pa':\n",
    "                tempseasonal /= 100.\n",
    "                modelUnits = 'hPa'\n",
    "            elif ((modelUnits == 'm/s') & (varname == 'PREC')):\n",
    "                # switch to monthly average precipitation for the season\n",
    "                if season == 'DJF':\n",
    "                    secPerMonth = 60*60*24*90/3.\n",
    "                elif ((season == 'JJA') | (season == 'MAM')):\n",
    "                    secPerMonth = 60*60*24*92/3.\n",
    "                elif season == 'SON':\n",
    "                    secPerMonth = 60*60*24*91/3.\n",
    "                elif season == 'ALL':\n",
    "                    secPerMonth = 60*60*24*365/12.\n",
    "                    \n",
    "                tempseasonal *= 1e3*secPerMonth # average cumulative precip per month, millimeters\n",
    "                \n",
    "            # calculate the global average value\n",
    "            wgts = np.cos(lat*np.pi/180.)\n",
    "            wgtsMat = (np.repeat(wgts[:, np.newaxis], mlon, axis = -1))[np.newaxis, :, :]\n",
    "            globalMeanTemp[:, counter] = np.sum(tempseasonal.reshape((nyrs, mlat*mlon))*wgtsMat.reshape((1, mlat*mlon)), axis = -1)/np.sum(wgtsMat.flatten())\n",
    "\n",
    "        # calculate average across simulations for forced signal\n",
    "        EMglobal = np.mean(globalMeanTemp, axis = -1)\n",
    "\n",
    "        # save \n",
    "        np.save(emTrendFile, EMglobal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put model and observations in same format (varnames, grids, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check which grid is coarser\n",
    "fModel = Dataset(namesHist[0], 'r')\n",
    "latModel = fModel.variables['lat'][:]\n",
    "lonModel = fModel.variables['lon'][:]\n",
    "avgDlatModel = np.mean(np.abs(latModel[1:] - latModel[:-1]))\n",
    "\n",
    "fData = Dataset(dataDir + dataName, 'r')\n",
    "try:\n",
    "    latData = fData.variables['lat'][:]\n",
    "    lonData = fData.variables['lon'][:]\n",
    "except:\n",
    "    latData = fData.variables['latitude'][:]\n",
    "    lonData = fData.variables['longitude'][:]\n",
    "    \n",
    "avgDlatData = np.mean(np.abs(latData[1:] - latData[:-1]))\n",
    "\n",
    "# Pull out units\n",
    "obsUnits = fData.variables[varname].units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spharm\n",
    "\n",
    "# create spharm objects for regridding\n",
    "nlatM, nlonM = np.shape(latModel)[0], np.shape(lonModel)[0]\n",
    "nlatD, nlonD = np.shape(latData)[0], np.shape(lonData)[0]\n",
    "\n",
    "if ((obsname == 'BEST')) | ((obsname == '20CRV2c')) | (obsname == 'GPCC') | (obsname == 'NCEP'):\n",
    "    spM = spharm.Spharmt(nlonM, nlatM, gridtype = 'regular', legfunc = 'computed')\n",
    "    spD = spharm.Spharmt(nlonD, nlatD, gridtype = 'regular', legfunc = 'computed')\n",
    "else:\n",
    "    print 'Need to add functionality for other grids'\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "if avgDlatData > avgDlatModel:\n",
    "    # regrid model to data grid\n",
    "    print 'Regridding model to data grid'\n",
    "    \n",
    "    # first switch everything to 0,360\n",
    "    lonData[lonData < 0] = lonData[lonData < 0] + 360\n",
    "    idxLon = np.argsort(lonData) # remember to switch the data as well! \n",
    "    lon = np.sort(lonData)\n",
    "        \n",
    "    # change data latitude to increasing if it is not\n",
    "    idxLat = np.argsort(latData) # remember to switch the data as well! \n",
    "    lat = np.sort(latData)\n",
    "        \n",
    "    # check that latitude is increasing, and longitude is greater than zero\n",
    "    if (np.min(lon) < 0) | (np.min(lonModel) < 0) | (lat[-1] < lat[0]) | (latModel[-1] < latModel[0]):\n",
    "        raise KeyboardInterrupt\n",
    "    \n",
    "    nlat, nlon = np.shape(lat)[0], np.shape(lon)[0]\n",
    "    \n",
    "    # take seasonal averages for the data\n",
    "    saveNameObs = dataoutput + obsname + '.' + season + '.' + str(yrStart) + '.' + str(yrEnd) + '.' + varname + '.nc'\n",
    "    \n",
    "    if (not os.path.isfile(saveNameObs)):\n",
    "    \n",
    "        time = fData.variables['time'][:]\n",
    "        if obsname == 'BEST':\n",
    "            year = time.astype(int)\n",
    "            month = np.ceil((time - year)*12).astype(int)\n",
    "        elif ((obsname == '20CRV2c') | (obsname == 'GPCC')) | (obsname == 'NCEP'):\n",
    "            from netcdftime import utime\n",
    "            cdftime = utime(fData.variables['time'].units)\n",
    "            t = cdftime.num2date(fData.variables['time'][:])\n",
    "            year = np.array([(t[counter]).year for counter in np.arange(np.shape(t)[0])])\n",
    "            month = np.array([(t[counter]).month for counter in np.arange(np.shape(t)[0])])\n",
    "\n",
    "        idx1 = (year >= yrStart - 1) & (year <= yrEnd) # need one year earlier for the D in DJF\n",
    "        T = fData.variables[varname][idx1, :, :]\n",
    "        T = T[:, :, idxLon] # re-order the longitudes \n",
    "        T = T[:, idxLat, :] # and latitudes if necessary\n",
    "\n",
    "        # put into pandas\n",
    "        time = pd.date_range(start = '1/1/' + str(yrStart - 1), periods = np.shape(T)[0], freq = 'M')\n",
    "        tempseasonal = np.empty((nyrs, nlat, nlon))\n",
    "        timeseasonal = []\n",
    "        for ct in np.arange(nyrs):\n",
    "            yr = yrs[ct]\n",
    "            if season == 'DJF':\n",
    "                idxTime = (((time.month >= 1) & (time.month <= 2)) & (time.year == yr)) | \\\n",
    "                    (((time.month == 12) & (time.year == yr - 1)))\n",
    "            elif season == 'JJA':\n",
    "                idxTime = ((time.month >= 6) & (time.month <= 8)) & (time.year == yr)\n",
    "            elif season == 'MAM':\n",
    "                idxTime = ((time.month >= 3) & (time.month <= 5)) & (time.year == yr)\n",
    "            elif season == 'SON':\n",
    "                idxTime = ((time.month >= 9) & (time.month <= 11)) & (time.year == yr)\n",
    "            elif season == 'ALL':\n",
    "                idxTime = (time.year == yr)\n",
    "            else:\n",
    "                print 'Need to specify a canonical 3 month season'\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "            tempseasonal[ct, :, :] = np.mean(T[idxTime, :, :], axis = 0)\n",
    "            timeseasonal.append(pd.to_datetime((time[idxTime])[-1]))\n",
    "\n",
    "        # change to hPa\n",
    "        if obsUnits == 'Pa':\n",
    "            tempseasonal /= 100.\n",
    "            obsUnits = 'hPa'\n",
    "        elif obsUnits == 'millibars':\n",
    "            obsUnits = 'hPa'\n",
    "            \n",
    "        # save to netcdf\n",
    "        fout = Dataset(saveNameObs, 'w')\n",
    "\n",
    "        fout.createDimension('lat', nlat)\n",
    "        fout.createDimension('lon', nlon)\n",
    "        fout.createDimension('time', 0)\n",
    "\n",
    "        latnc = fout.createVariable('lat', 'f8', ('lat',))\n",
    "        lonnc = fout.createVariable('lon', 'f8', ('lon',))\n",
    "        timenc = fout.createVariable('time', 'f8', ('time',))\n",
    "        tempnc = fout.createVariable(varname, 'f8', ('time','lat','lon'))\n",
    "\n",
    "        fout.description = season + ' average ' + varname + ' from ' + obsname\n",
    "\n",
    "        latnc.units = 'degree_north'\n",
    "        lonnc.units = 'degree_east'\n",
    "        tempnc.units = obsUnits\n",
    "        timenc.units = 'days since 1850-01-01 00:00:00'\n",
    "        timenc.calendar = 'gregorian'\n",
    "\n",
    "        latnc[:] = lat\n",
    "        lonnc[:] = lon\n",
    "        tempnc[:, :, :] = tempseasonal\n",
    "\n",
    "        from datetime import datetime, timedelta\n",
    "        from netCDF4 import num2date, date2num\n",
    "\n",
    "        timenc[:] = date2num(timeseasonal, units = timenc.units)\n",
    "\n",
    "        fout.close()   \n",
    "    \n",
    "    \n",
    "    for counter in np.arange(len(namesHist)):\n",
    "\n",
    "        # read in historical simulation for first part\n",
    "        ensNumber = (((namesHist[counter].split('/'))[-1]).split('.'))[4]\n",
    "        \n",
    "        # name to save regridded output\n",
    "        saveName = LENSoutput + 'LENS.' + season + '.' + str(yrStart) + '.' + str(yrEnd) + '.' + varname + '.regridded.to.' + obsname + '.' + ensNumber + '.nc'\n",
    "        \n",
    "        if (not os.path.isfile(saveName)):\n",
    "            print 'Taking seasonal averages and regridding member ' + ensNumber\n",
    "\n",
    "            timeSpan = (((namesHist[counter].split('/'))[-1]).split('.'))[-2]\n",
    "            fileBeginYr = (str(timeSpan)[:4])\n",
    "            fileBeginMo = (str(timeSpan)[4:6])\n",
    "            fileEndYr = int(str(timeSpan)[7:11])\n",
    "            fileEndMo = int(str(timeSpan)[11:13])\n",
    "            fid1 = Dataset(namesHist[counter], 'r')\n",
    "            time0 = fid1.variables['time'][:]\n",
    "            ntime = time0.shape[0]\n",
    "            time1 = pd.date_range(fileBeginMo + '/15/' + fileBeginYr, periods = ntime, freq = 'M')\n",
    "\n",
    "            if varname == 'PREC':\n",
    "                modelUnits = fid1.variables[varname + 'C'].units\n",
    "            else:\n",
    "                modelUnits = fid1.variables[varname].units\n",
    "            # load in values that are in the timespan\n",
    "            idx1 = (time1.year >= yrStart - 1) & (time1.year <= yrEnd) # need one year earlier for the D in DJF\n",
    "\n",
    "            if is3d:\n",
    "                lev = fid1.variables['lev'][:]\n",
    "                idxLev = np.argmin(np.abs(lev - levUse))\n",
    "                T1 = (fid1.variables[varname][idx1, idxLev, :, :]).squeeze()\n",
    "            elif varname == 'PREC':\n",
    "                fid1L = Dataset(namesHistL[counter], 'r')\n",
    "                T1L = fid1L.variables[varname + 'L'][idx1, :, :] # large scale\n",
    "                T1C = fid1.variables[varname + 'C'][idx1, :, :] # convective\n",
    "                T1 = T1L + T1C\n",
    "            else:\n",
    "                T1 = fid1.variables[varname][idx1, :, :]\n",
    "\n",
    "            # now read in future\n",
    "            timeSpan = (((namesFuture[counter].split('/'))[-1]).split('.'))[-2]\n",
    "            fileBeginYr = (str(timeSpan)[:4])\n",
    "            fileBeginMo = (str(timeSpan)[4:6])\n",
    "            fileEndYr = int(str(timeSpan)[7:11])\n",
    "            fileEndMo = int(str(timeSpan)[11:13])\n",
    "\n",
    "            fid2 = Dataset(namesFuture[counter], 'r')\n",
    "            time0 = fid2.variables['time'][:]\n",
    "            ntime = time0.shape[0]\n",
    "            time2 = pd.date_range(fileBeginMo + '/15/' + fileBeginYr, periods = ntime, freq = 'M')\n",
    "\n",
    "            # load in values that are in the timespan\n",
    "            idx2 = (time2.year >= yrStart - 1) & (time2.year <= yrEnd) # need one year earlier for the D in DJF\n",
    "\n",
    "            if is3d:\n",
    "                lev = fid2.variables['lev'][:]\n",
    "                idxLev = np.argmin(np.abs(lev - levUse))\n",
    "                T2 = (fid2.variables[varname][idx2, idxLev, :, :]).squeeze()\n",
    "            elif varname == 'PREC':\n",
    "                fid2L = Dataset(namesFutureL[counter], 'r')\n",
    "                T2L = fid2L.variables[varname + 'L'][idx2, :, :] # large scale\n",
    "                T2C = fid2.variables[varname + 'C'][idx2, :, :] # convective\n",
    "                T2 = T2L + T2C\n",
    "            else:\n",
    "                T2 = fid2.variables[varname][idx2, :, :]\n",
    "\n",
    "            T = np.concatenate((T1, T2), axis = 0)\n",
    "\n",
    "            time = pd.date_range('1/1/' + str(yrStart - 1), periods = T.shape[0], freq = 'M')\n",
    "            \n",
    "            tempseasonal = np.empty((nyrs, nlat, nlon))\n",
    "            timeseasonal = []\n",
    "            for ct in np.arange(nyrs):\n",
    "                yr = yrs[ct]\n",
    "                if season == 'DJF':\n",
    "                    idxTime = (((time.month >= 1) & (time.month <= 2)) & (time.year == yr)) | \\\n",
    "                        (((time.month == 12) & (time.year == yr - 1)))\n",
    "                elif season == 'JJA':\n",
    "                    idxTime = ((time.month >= 6) & (time.month <= 8)) & (time.year == yr)\n",
    "                elif season == 'MAM':\n",
    "                    idxTime = ((time.month >= 3) & (time.month <= 5)) & (time.year == yr)\n",
    "                elif season == 'SON':\n",
    "                    idxTime = ((time.month >= 9) & (time.month <= 11)) & (time.year == yr)\n",
    "                elif season == 'ALL':\n",
    "                    idxTime = (time.year == yr)\n",
    "                else:\n",
    "                    print 'Need to specify a canonical 3 month season'\n",
    "                    raise KeyboardInterrupt\n",
    "                    \n",
    "                dummy = np.mean(T[idxTime, :, :], axis = 0)\n",
    "\n",
    "                # regrid(grid in, grid out)\n",
    "                data_interp = spharm.regrid(spM, spD, dummy)\n",
    "\n",
    "                tempseasonal[ct, :, :] = data_interp\n",
    "                timeseasonal.append(pd.to_datetime((time[idxTime])[-1])) \n",
    "            \n",
    "            # change units for temperature\n",
    "            if modelUnits == 'K':\n",
    "                tempseasonal -= 273.15\n",
    "                modelUnits = 'degC'\n",
    "            elif modelUnits == 'Pa':\n",
    "                tempseasonal /= 100.\n",
    "                modelUnits = 'hPa'\n",
    "            elif ((modelUnits == 'm/s') & (varname == 'PREC')):\n",
    "                # switch to monthly average precipitation for the season\n",
    "                if season == 'DJF':\n",
    "                    secPerMonth = 60*60*24*90/3.\n",
    "                elif ((season == 'JJA') | (season == 'MAM')):\n",
    "                    secPerMonth = 60*60*24*92/3.\n",
    "                elif season == 'SON':\n",
    "                    secPerMonth = 60*60*24*91/3.\n",
    "                elif season == 'ALL':\n",
    "                    secPerMonth = 60*60*24*365/12.\n",
    "                    \n",
    "                tempseasonal *= 1e3*secPerMonth # average cumulative precip per month, millimeters\n",
    "                modelUnits = 'mm/mn' # mm/month to match obs\n",
    "            elif modelUnits == 'm':\n",
    "                print 'Units all good!'\n",
    "            else:\n",
    "                print 'check whether units need to be changed'\n",
    "                raise KeyboardInterrupt\n",
    "                \n",
    "            # save to netcdf\n",
    "            fout = Dataset(saveName, 'w')\n",
    "\n",
    "            fout.createDimension('lat', nlat)\n",
    "            fout.createDimension('lon', nlon)\n",
    "            fout.createDimension('time', 0)\n",
    "\n",
    "            latnc = fout.createVariable('lat', 'f8', ('lat',))\n",
    "            lonnc = fout.createVariable('lon', 'f8', ('lon',))\n",
    "            timenc = fout.createVariable('time', 'f8', ('time',))\n",
    "            tempnc = fout.createVariable(varname, 'f8', ('time','lat','lon'))\n",
    "\n",
    "            fout.description = season + ' average ' + varname + ' from LENS regridded to ' + obsname + ' grid'\n",
    "\n",
    "            latnc.units = 'degree_north'\n",
    "            lonnc.units = 'degree_east'\n",
    "            tempnc.units = modelUnits\n",
    "            timenc.units = 'days since 1850-01-01 00:00:00'\n",
    "            timenc.calendar = 'gregorian'\n",
    "\n",
    "            latnc[:] = latData\n",
    "            lonnc[:] = lonData\n",
    "            tempnc[:, :, :] = tempseasonal\n",
    "\n",
    "            from datetime import datetime, timedelta\n",
    "            from netCDF4 import num2date, date2num\n",
    "\n",
    "            timenc[:] = date2num(timeseasonal, units = timenc.units)\n",
    "\n",
    "            fout.close()         \n",
    "    \n",
    "else:\n",
    "    # regrid data to model grid\n",
    "    print 'Not currently an option to regrid data to model grid'\n",
    "    raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create ensemble mean\n",
    "fNamesMembers = sorted(glob.glob(LENSoutput + 'LENS.' + season + '.' + str(yrStart) + '.' + str(yrEnd) + '.' + varname + '.regridded.to.' + obsname + '*[^0-9]*.nc'))\n",
    "fNameEM = LENSoutput + 'LENS.' + season + '.' + str(yrStart) + '.' + str(yrEnd) + '.' + varname + '.regridded.to.' + obsname + '.EM.nc'\n",
    "\n",
    "nlat, nlon = lat.shape[0], lon.shape[0]\n",
    "\n",
    "if (not os.path.isfile(fNameEM)):\n",
    "\n",
    "    EM = np.empty((nyrs, nlat, nlon, len(fNamesMembers)))\n",
    "    for counter, f in enumerate(fNamesMembers):\n",
    "        ds = Dataset(f, 'r')\n",
    "        EM[:, :, :, counter] = ds.variables[varname][:]\n",
    "\n",
    "    modelUnits = ds.variables[varname].units\n",
    "\n",
    "    time = ds.variables['time'][:]\n",
    "    EM = np.mean(EM, axis = -1)\n",
    "    fout = Dataset(fNameEM, 'w')\n",
    "\n",
    "    fout.createDimension('lat', nlat)\n",
    "    fout.createDimension('lon', nlon)\n",
    "    fout.createDimension('time', 0)\n",
    "\n",
    "    latnc = fout.createVariable('lat', 'f8', ('lat',))\n",
    "    lonnc = fout.createVariable('lon', 'f8', ('lon',))\n",
    "    timenc = fout.createVariable('time', 'f8', ('time',))\n",
    "    tempnc = fout.createVariable(varname, 'f8', ('time','lat','lon'))\n",
    "\n",
    "    fout.description = season + ' average temperatures from CESM LE EM'\n",
    "\n",
    "    latnc.units = 'degree_north'\n",
    "    lonnc.units = 'degree_east'\n",
    "    tempnc.units = modelUnits\n",
    "    timenc.units = 'days since 1850-01-01 00:00:00'\n",
    "    timenc.calendar = 'gregorian'\n",
    "\n",
    "    latnc[:] = lat\n",
    "    lonnc[:] = lon\n",
    "    tempnc[:, :, :] = EM\n",
    "    timenc[:] = time\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping\n",
    "\n",
    "Model: T$_t$ = $\\beta_0$ + $\\beta_1$ x trend$_t$ + $\\beta_{2,n}$ x modes$_t$ + $\\epsilon_t$\n",
    "\n",
    "Estimate all parameters from the full time series (e.g. 1921-2015, or set by user)\n",
    "\n",
    "Create synthetic time series by randomly generating new versions of $\\beta_{2,n}$ x modes$_t$ + $\\epsilon_t$ while keeping the first two terms of the model, $\\beta_0$ + $\\beta_1$ x trend$_t$, fixed across all samples\n",
    "\n",
    "The modes term is generated by creating surrogate versions of modes$_t$ via phase shuffling.\n",
    "\n",
    "The $\\epsilon_t$ term is bootstrapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file to save bootstrapping output\n",
    "# putting in scratch space because can be big, and doesn't take that long to re-run\n",
    "\n",
    "useModes = 1\n",
    "bootOutputName = scratchDir + 'bootstrap.modes.' + str(useModes) + '.' + str(paramHash) + '.npz'\n",
    "# save statistics of bootstrap samples here\n",
    "bootOutputSummaryName = outputDir + 'bootstrapSummary.modes.' + str(useModes) + '.' + str(paramHash) + '.npz'\n",
    "# save the modified bootstrap output -- modes or bootstrap only\n",
    "bootOutputNameMod1 = scratchDir + 'bootstrap.modes.' + str(useModes) + '.' + str(paramHash) + '.mod1.npz'\n",
    "bootOutputNameMod2 = scratchDir + 'bootstrap.modes.' + str(useModes) + '.' + str(paramHash) + '.mod2.npz'\n",
    "\n",
    "#obsBootOutputName = scratchDir + 'bootstrap.modes.obs.' + str(paramHash) + '.npz'\n",
    "#obsBootOutputSummaryName = outputDir + 'bootstrapSummary.modes.obs.' + str(paramHash) + '.npz'\n",
    "     \n",
    "# stack files such that the order is EM, all model members, then obs\n",
    "fnames = list(fNamesMembers)\n",
    "fnames.insert(0, fNameEM)\n",
    "fnames.append(saveNameObs)\n",
    "\n",
    "\n",
    "# Stack mode matrices\n",
    "modeValsAll = np.dstack((np.mean(modeValNormO_LENS, axis = -1)[:, :, np.newaxis]\n",
    "                        , modeValNormO_LENS, modeValNormO[:, :, np.newaxis]))\n",
    "\n",
    "print bootOutputName\n",
    "print bootOutputSummaryName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yrs0 = yrs - np.mean(yrs)\n",
    "yrsTrend0 = yrsTrend - np.mean(yrsTrend)\n",
    "\n",
    "# what trend should be removed when calculating interannual variability?\n",
    "if trendType1 == 'linear': \n",
    "    X = np.matrix(np.hstack((np.ones((nyrs, 1)), yrs0[:, np.newaxis])))\n",
    "elif trendType1 == 'quad':\n",
    "    X = np.matrix(np.hstack((np.ones((nyrs, 1)), yrs0[:, np.newaxis], (yrs0[:, np.newaxis])**2)))\n",
    "elif trendType1 == 'EM': \n",
    "    EM = np.load(emTrendFile)\n",
    "    EM_anom = EM - np.mean(EM)\n",
    "    X = np.matrix(np.hstack((np.ones((nyrs, 1)), EM_anom[:, np.newaxis])))\n",
    "    \n",
    "# what should be used as a covariate in calculating trends?\n",
    "if trendType2 == 'linear': \n",
    "    X0 = np.matrix(np.hstack((np.ones((nyrsTrend, 1)), yrsTrend0[:, np.newaxis])))\n",
    "elif trendType2 == 'quad':\n",
    "    X0 = np.matrix(np.hstack((np.ones((nyrsTrend, 1)), yrsTrend0[:, np.newaxis], (yrsTrend0[:, np.newaxis])**2)))\n",
    "elif trendType2 == 'EM': \n",
    "    EM = np.load(emTrendFile)\n",
    "    # pull out matching period\n",
    "    EMsub = EM[np.in1d(yrs, yrsTrend)]\n",
    "    EM_anom = EMsub - np.mean(EMsub)\n",
    "    X0 = np.matrix(np.hstack((np.ones((nyrsTrend, 1)), EM_anom[:, np.newaxis])))\n",
    "\n",
    "# set to unity standard deviation \n",
    "X[:, 1:] = (X[:, 1:] - np.mean(X[:, 1:], axis = 0))/np.std(X[:, 1:], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to change temp directory in order to save large numpy file to a place that has lots of space \n",
    "import tempfile\n",
    "tempfile.tempdir = scratchDir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine temporal properties of residuals for OLENS\n",
    "f = fnames[-1]\n",
    "ds = Dataset(f, 'r') \n",
    "T = ds.variables[varname][:]\n",
    "if obsname == 'Hadley': # missing data case\n",
    "    T = np.ma.masked_where(np.isnan(T), T)\n",
    "Tvec = np.matrix(T.reshape((nyrs, nlon*nlat))) # time by space\n",
    "\n",
    "if useModes:\n",
    "    modeTS = modeValsAll[:, :, -1]\n",
    "    Xnew = np.hstack((X, modeTS))\n",
    "\n",
    "else:\n",
    "    Xnew = X.copy()\n",
    "\n",
    "# trend as a function of predictor (time or EM temperature trend) in order to estimate residuals\n",
    "# Modeling both the forced trend and the modes here\n",
    "beta = (np.dot(np.dot((np.dot(Xnew.T, Xnew)).I, Xnew.T), Tvec)) \n",
    "\n",
    "trendEst = np.dot(Xnew, beta) # best fit to predictor\n",
    "resVals = np.array(Tvec - trendEst) # residuals (to be bootstrapped)\n",
    "oceanmask = np.ma.getmask(maskOceansKAM(lon, lat, resVals[0,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = np.meshgrid(lon, lat)\n",
    "lons, lats = lons.flatten(), lats.flatten()\n",
    "from pypr.stattest.ljungbox import *\n",
    "idxLand = np.where((~oceanmask )& (lats > -60))[0]\n",
    "LBstat = 2*np.ones((nlat*nlon,))\n",
    "for ii in idxLand:\n",
    "    x = resVals[:, ii]\n",
    "    h, pV, Q, cV = lbqtest(x, range(20,21), alpha = 0.05)\n",
    "    LBstat[ii] = h[0]\n",
    "    \n",
    "wgts = np.sqrt(np.cos(np.deg2rad(lats)))\n",
    "idxWhite = 1 - np.sum(wgts[idxLand]*LBstat[idxLand])/np.sum(wgts)\n",
    "print str(np.round(idxWhite, 2)) + ' fraction of land area is white noise for ' + varname + ' in ' + season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save members of OLENS \n",
    "\n",
    "# set seed so can compare, e.g., PSL and TREFHT\n",
    "np.random.seed(123)\n",
    "\n",
    "# Load in observations\n",
    "ds = Dataset(saveNameObs, 'r') \n",
    "T = ds.variables[varname][:]\n",
    "if obsname == 'Hadley': # missing data case\n",
    "    T = np.ma.masked_where(np.isnan(T), T)\n",
    "Tvec = np.matrix(T.reshape((nyrs, nlon*nlat))) # time by space\n",
    "\n",
    "# Get predictors (constant, forced component, trend)\n",
    "modeTS = modeValsAll[:, :, -1]\n",
    "Xnew = np.hstack((X, modeTS))\n",
    "\n",
    "# trend as a function of predictor (time or EM temperature trend) in order to estimate residuals\n",
    "# Modeling both the forced trend and the modes here\n",
    "beta = (np.dot(np.dot((np.dot(Xnew.T, Xnew)).I, Xnew.T), Tvec)) \n",
    "\n",
    "trendEst = np.dot(Xnew, beta) # best fit to predictor\n",
    "resVals = Tvec - trendEst # residuals (to be bootstrapped)\n",
    "\n",
    "SAMPLES = np.empty((nyrs, nlat*nlon, nboot))\n",
    "\n",
    "trendEst0 = np.dot(X, beta[:2, :])\n",
    "\n",
    "for kk in np.arange(nboot):\n",
    "\n",
    "    if np.mod(nyrs, blocksize) == 0:\n",
    "\n",
    "        numSeeds = nyrs/blocksize\n",
    "        sampleIdx = np.random.randint(0, nyrs, numSeeds)\n",
    "        idxUse = (np.array([np.arange(sampleIdx[jj], sampleIdx[jj] + blocksize) for jj in np.arange(np.shape(sampleIdx)[0])])).ravel()\n",
    "        idxUse = np.mod(idxUse, nyrs)\n",
    "\n",
    "    else:\n",
    "\n",
    "        numSeeds = nyrs/blocksize\n",
    "        sampleIdx = np.random.randint(0, nyrs, numSeeds)\n",
    "        idxUse = (np.array([np.arange(sampleIdx[jj], sampleIdx[jj] + blocksize) for jj in np.arange(np.shape(sampleIdx)[0])])).ravel()\n",
    "        timeLeft = np.mod(nyrs, blocksize)\n",
    "        sampleLeftover = np.random.randint(0, nyrs, 1) # just going to have one set of randoms \n",
    "        idxUse2 = np.arange(sampleLeftover, sampleLeftover + timeLeft)\n",
    "        idxUse = np.append(idxUse, idxUse2)\n",
    "        idxUse = np.mod(idxUse, nyrs)\n",
    "\n",
    "\n",
    "    # create surrogate versions of the modes\n",
    "    surrogateMode = np.empty_like(modeTS)\n",
    "    for mm in np.arange(modeTS.shape[-1]):\n",
    "        ts = modeValNormO[:, mm]\n",
    "        dummy = create_surrogates_1d(ts)\n",
    "        # do adjustment so overall variance matches\n",
    "        dummy *= np.std(ts)/np.std(dummy)\n",
    "        surrogateMode[:, mm] = dummy\n",
    "\n",
    "    trendEstModes = np.dot(surrogateMode, beta[-nModes:, :])\n",
    "    SAMPLES[:, :, kk] = trendEst0 + trendEstModes + resVals[idxUse, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recenter samples on LENS EM for OLENS\n",
    "dsEM = Dataset(fNameEM, 'r')\n",
    "EMvals = dsEM[varname][:]\n",
    "EMvals = EMvals.reshape((nyrs, nlat*nlon))\n",
    "OLENS = (SAMPLES - np.mean(SAMPLES, -1)[:, :, np.newaxis] + EMvals[:, :, np.newaxis]).reshape((nyrs, nlat, nlon, nboot))\n",
    "\n",
    "# Define units\n",
    "if ((varname == 'TREFHT') | (varname == 'T') | (varname == 'TS')):\n",
    "    unitsName = 'degC'\n",
    "elif varname == 'PSL':\n",
    "    unitsName = 'hPa'\n",
    "elif varname == 'Z3':\n",
    "    unitsName = 'm'\n",
    "elif varname == 'PREC':\n",
    "    unitsName = 'mm/mo'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to a netcdf\n",
    "# Need to divide into 10 files in order to fit into dataverse\n",
    "nfiles = 20\n",
    "samples_per_file = nboot/nfiles\n",
    "\n",
    "for filect in np.arange(nfiles):\n",
    "\n",
    "    savename = '/glade/scratch/mckinnon/OLENS/%s_%s_%i-%i_file%02d.nc' \\\n",
    "        % (varname, season, yrs[0], yrs[-1], filect + 1)\n",
    "        \n",
    "    print(savename)\n",
    "    time = dsEM.variables['time'][:]\n",
    "    fout = Dataset(savename, 'w')\n",
    "    \n",
    "    samplesSave = np.arange(filect*samples_per_file, samples_per_file*(filect+1))\n",
    "\n",
    "    fout.createDimension('lat', nlat)\n",
    "    fout.createDimension('lon', nlon)\n",
    "    fout.createDimension('samples', samples_per_file)\n",
    "    fout.createDimension('time', 0)\n",
    "\n",
    "    latnc = fout.createVariable('lat', 'f8', ('lat',))\n",
    "    lonnc = fout.createVariable('lon', 'f8', ('lon',))\n",
    "    timenc = fout.createVariable('time', 'f8', ('time',))\n",
    "    samplenc = fout.createVariable('samples', 'i', ('samples',))\n",
    "    tempnc = fout.createVariable(varname, 'f8', ('time','lat','lon', 'samples'))\n",
    "\n",
    "    fout.description = (\"Samples of %s %s from the Observational Large Ensemble (OLENS). \"\n",
    "                        \"Data is from %s. \"  \n",
    "                       \"The forced component of OLENS is the ensemble mean of 40 members of the \"\n",
    "                       \"NCAR CESM1 Large Ensemble. \"\n",
    "                       \"See McKinnon and Deser, J Clim, for more details.\" % (season, varname, obsname))\n",
    "\n",
    "    latnc.units = 'degree_north'\n",
    "    lonnc.units = 'degree_east'\n",
    "    tempnc.units = unitsName\n",
    "    timenc.units = 'days since 1850-01-01 00:00:00'\n",
    "    timenc.calendar = 'gregorian'\n",
    "\n",
    "    latnc[:] = lat\n",
    "    lonnc[:] = lon\n",
    "    samplenc[:] = samplesSave + 1\n",
    "    tempnc[:, :, :, :] = OLENS[:, :, :, filect*samples_per_file:samples_per_file*(filect+1)]\n",
    "    timenc[:] = time\n",
    "\n",
    "    fout.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bootstrapping, and then calculate trends across samples over desired period\n",
    "\n",
    "if (not os.path.isfile(bootOutputName)): # if not already done\n",
    "\n",
    "    # set seed so can compare, e.g., PSL and TREFHT\n",
    "    np.random.seed(123)\n",
    "\n",
    "    BETA = np.empty((len(fnames), nlat*nlon)) # empirical trends (actual)\n",
    "    BOOTSAMPLES = np.empty((len(fnames), nlat*nlon, nboot)) # bootstrapped trends\n",
    "    BOOTSAMPLES_MOD1 = BOOTSAMPLES.copy()\n",
    "    BOOTSAMPLES_MOD2 = BOOTSAMPLES.copy()\n",
    "    INTERANNUALVAR = np.empty((len(fnames), nlat*nlon)) # variance across time\n",
    "    empiricalAR1 = np.empty((len(fnames), nlat*nlon)) # estimated AR(1) coefficient\n",
    "    \n",
    "    for ii, f in enumerate(fnames):\n",
    "\n",
    "        print f\n",
    "\n",
    "        ds = Dataset(f, 'r')\n",
    "        T = ds.variables[varname][:]\n",
    "        if obsname == 'Hadley': # missing data case\n",
    "            T = np.ma.masked_where(np.isnan(T), T)\n",
    "        Tvec = np.matrix(T.reshape((nyrs, nlon*nlat))) # time by space\n",
    "        \n",
    "        if useModes:\n",
    "            modeTS = modeValsAll[:, :, ii]\n",
    "            Xnew = np.hstack((X, modeTS))\n",
    "\n",
    "        else:\n",
    "            Xnew = X.copy()\n",
    "        \n",
    "        # trend as a function of predictor (time or EM temperature trend) in order to estimate residuals\n",
    "        # Modeling both the forced trend and the modes here\n",
    "        beta = (np.dot(np.dot((np.dot(Xnew.T, Xnew)).I, Xnew.T), Tvec)) \n",
    "        \n",
    "        Tvecsub = Tvec[np.in1d(yrs, yrsTrend), :]\n",
    "        beta0 = (np.dot(np.dot((np.dot(X0.T, X0)).I, X0.T), Tvecsub)) # trend over period of interest\n",
    "        BETA[ii, :] = beta0[-1, :]\n",
    "\n",
    "        trendEst = np.dot(Xnew, beta) # best fit to predictor\n",
    "        resVals = Tvec - trendEst # residuals (to be bootstrapped)\n",
    "\n",
    "        \n",
    "        # trend estimate from intercept and trend model only (no modes)\n",
    "        trendEst0 = np.dot(X, beta[:2, :])\n",
    "        \n",
    "        # calculate autocorrelation for lag 1\n",
    "        empiricalAR1[ii, :] = np.array([autocorr(np.array(resVals[:, gg]).flatten()) for gg in np.arange(nlat*nlon)])[:, 1]\n",
    "        \n",
    "        # calculate year-to-year variance\n",
    "        INTERANNUALVAR[ii, :] = np.var(resVals, axis = 0, ddof = 2) # 2 less degrees of freedom: mean and trend\n",
    "        \n",
    "        for kk in np.arange(nboot):\n",
    "            \n",
    "            if np.mod(nyrs, blocksize) == 0:\n",
    "                \n",
    "                numSeeds = nyrs/blocksize\n",
    "                sampleIdx = np.random.randint(0, nyrs, numSeeds)\n",
    "                idxUse = (np.array([np.arange(sampleIdx[jj], sampleIdx[jj] + blocksize) for jj in np.arange(np.shape(sampleIdx)[0])])).ravel()\n",
    "                idxUse = np.mod(idxUse, nyrs)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                numSeeds = nyrs/blocksize\n",
    "                sampleIdx = np.random.randint(0, nyrs, numSeeds)\n",
    "                idxUse = (np.array([np.arange(sampleIdx[jj], sampleIdx[jj] + blocksize) for jj in np.arange(np.shape(sampleIdx)[0])])).ravel()\n",
    "                timeLeft = np.mod(nyrs, blocksize)\n",
    "                sampleLeftover = np.random.randint(0, nyrs, 1) # just going to have one set of randoms \n",
    "                idxUse2 = np.arange(sampleLeftover, sampleLeftover + timeLeft)\n",
    "                idxUse = np.append(idxUse, idxUse2)\n",
    "                idxUse = np.mod(idxUse, nyrs)\n",
    "                \n",
    "                \n",
    "            # create surrogate versions of the modes\n",
    "            if useModes:\n",
    "                surrogateMode = np.empty_like(modeTS)\n",
    "                for mm in np.arange(modeTS.shape[-1]):\n",
    "                    ts = modeValNormO[:, mm]\n",
    "                    dummy = create_surrogates_1d(ts)\n",
    "                    # do adjustment so overall variance matches\n",
    "                    dummy *= np.std(ts)/np.std(dummy)\n",
    "                    surrogateMode[:, mm] = dummy\n",
    "                \n",
    "                trendEstModes = np.dot(surrogateMode, beta[-nModes:, :])\n",
    "                bootsample = trendEst0 + trendEstModes + resVals[idxUse, :]\n",
    "\n",
    "                # Do experiment: how much of variability is due to modes, versus due to atmospheric variability\n",
    "                # that is captured in the bootstrapping? \n",
    "                # Do modified bootsamples that only include one or the other\n",
    "                bootsampleMod1 = trendEst0 + trendEstModes # only modes\n",
    "                bootsampleMod2 = trendEst0 + resVals[idxUse, :] # exclude modes\n",
    "            else:\n",
    "                bootsample = trendEst0 + resVals[idxUse, :]\n",
    "                \n",
    "\n",
    "            bootsampleSub = bootsample[np.in1d(yrs, yrsTrend), :]\n",
    "            BOOTSAMPLES[ii, :, kk] = np.array((np.dot(np.dot((np.dot(X0.T, X0)).I, X0.T), bootsampleSub)))[-1, :]\n",
    "            \n",
    "            if useModes:\n",
    "                bootsampleSubMod1 = bootsampleMod1[np.in1d(yrs, yrsTrend), :]\n",
    "                bootsampleSubMod2 = bootsampleMod2[np.in1d(yrs, yrsTrend), :]\n",
    "                BOOTSAMPLES_MOD1[ii, :, kk] = np.array((np.dot(np.dot((np.dot(X0.T, X0)).I, X0.T), bootsampleSubMod1)))[-1, :]\n",
    "                BOOTSAMPLES_MOD2[ii, :, kk] = np.array((np.dot(np.dot((np.dot(X0.T, X0)).I, X0.T), bootsampleSubMod2)))[-1, :]\n",
    "            \n",
    "\n",
    "    BOOTSTD = np.std(BOOTSAMPLES, axis = -1)\n",
    "    np.savez_compressed(bootOutputSummaryName, BETA = BETA, BOOTSTD = BOOTSTD, \\\n",
    "                        INTERANNUALVAR = INTERANNUALVAR,empiricalAR1 = empiricalAR1)\n",
    "    \n",
    "    np.savez_compressed(bootOutputName, BETA = BETA, BOOTSAMPLES = BOOTSAMPLES)\n",
    "    \n",
    "    if useModes:\n",
    "        np.savez_compressed(bootOutputNameMod1, BOOTSAMPLES_MOD1 = BOOTSAMPLES_MOD1)\n",
    "        np.savez_compressed(bootOutputNameMod2, BOOTSAMPLES_MOD2 = BOOTSAMPLES_MOD2)\n",
    "    \n",
    "else:\n",
    "    print \"Loading bootstrap output\"\n",
    "    # print \"Not loading bootstrap samples for now, but load later for plots\"\n",
    "    loadName = bootOutputSummaryName\n",
    "    f = np.load(loadName)\n",
    "    BETA = f['BETA']\n",
    "    if loadName == bootOutputName:\n",
    "        BOOTSAMPLES = f['BOOTSAMPLES']\n",
    "    else:\n",
    "        BOOTSTD = f['BOOTSTD']\n",
    "        INTERANNUALVAR = f['INTERANNUALVAR']\n",
    "        empiricalAR1 = f['empiricalAR1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
